---
title: 我的杯麵
date: 2024-08-20
tags: [AI/ML, LLM, LangChain, HuggingFace, Chainlit]
---

# 我的杯麵

## 緣起

趁著年度特休閒著沒事做，心血來潮想要測試一下 nvidia 4070

## 參考

- [Hugging Face x LangChain : A new partner package in LangChain](https://huggingface.co/blog/langchain)
- [Using Phi-3 in Hugging Face](https://github.com/microsoft/Phi-3CookBook/blob/main/md/02.QuickStart/Huggingface_QuickStart.md)
- [突破 Transformers 的速度瓶頸！Flash-Attention 介紹](https://medium.com/@e0928021388/%E7%AA%81%E7%A0%B4-transformers-%E7%9A%84%E9%80%9F%E5%BA%A6%E7%93%B6%E9%A0%B8-flash-attention-%E4%BB%8B%E7%B4%B9-28c1bc667fd9)
- [Enable NVIDIA CUDA on WSL](https://learn.microsoft.com/zh-tw/windows/ai/directml/gpu-cuda-in-wsl)
- [CUDA support for WSL 2](https://docs.nvidia.com/cuda/wsl-user-guide/index.html#cuda-support-for-wsl-2)
- [CUDA Toolkit 12.6 Downloads](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_local)
- [MTEB leaderboard](https://huggingface.co/spaces/mteb/leaderboard)
